"""
consult_expert.py - Outil de d√©l√©gation vers mod√®les sp√©cialis√©s (MoA)

Permet √† Iris (Gemini Flash) de d√©l√©guer les t√¢ches complexes ou historiques
√† des mod√®les plus performants (Thinking, Pro) via un appel STATELESS.

L'expert ne re√ßoit QUE la query sp√©cifique (et √©ventuellement des extraits 
de documents), mais PAS l'historique de bavardage r√©cent d'Iris.

v1.0.0 - Architecture Mixture of Agents (MoA)
Date: 2026-01-20

Usage:
    from actions.consult_expert import consult_expert
    result = consult_expert(query="Analyse cette architecture", expertise="reasoning")
"""

import logging
from typing import Dict, Any, Optional
from pathlib import Path

# Import du provider Gemini existant
from utils.gemini_provider import GeminiProvider

logger = logging.getLogger(__name__)

# === MAPPING EXPERTISE ‚Üí MOD√àLE ===
# Ces mod√®les sont appel√©s de mani√®re stateless (one-shot)
# Note: √âviter les mod√®les 2.0 (d√©pr√©ci√©s le 31 mars 2026)
EXPERT_MODELS = {
    # Raisonnement profond, logique complexe, analyse multi-√©tapes
    "reasoning": "gemini-2.5-pro",
    
    # Stabilit√© factuelle, grande fen√™tre pour contexte documentaire
    "historian": "gemini-2.5-pro",
    
    # Optimis√© pour le code, architecture, debugging
    "coder": "gemini-2.5-flash",
}

# Mod√®le de fallback si expertise inconnue
DEFAULT_EXPERT_MODEL = "gemini-2.5-flash"

# Instructions syst√®me par type d'expertise
EXPERT_INSTRUCTIONS = {
    "reasoning": """Tu es un expert en raisonnement logique et analyse complexe.
Ta t√¢che : analyser rigoureusement la question pos√©e.

M√âTHODE :
1. D√©compose le probl√®me en sous-parties
2. Analyse chaque partie de mani√®re explicite
3. Montre ton raisonnement √©tape par √©tape
4. Identifie les ambigu√Øt√©s ou informations manquantes
5. Conclus avec une r√©ponse claire et justifi√©e

Si tu n'as pas assez d'informations pour conclure, dis-le explicitement.
Ne fais JAMAIS d'hypoth√®ses non fond√©es.""",

    "historian": """Tu es un expert historien charg√© de v√©rifier des faits pass√©s.
Ta t√¢che : fournir des informations factuelles et dat√©es.

R√àGLES STRICTES :
1. R√©ponds UNIQUEMENT avec les informations que tu connais avec certitude
2. Si tu n'es pas s√ªr d'une date ou d'un fait, dis-le EXPLICITEMENT
3. Ne fais AUCUNE supposition - mieux vaut dire "je ne sais pas" que d'inventer
4. Cite tes sources de connaissance quand possible
5. Distingue clairement les faits des interpr√©tations

IMPORTANT : Tu re√ßois parfois du contexte documentaire provenant de la m√©moire
de l'utilisateur. Utilise-le comme source primaire d'information.""",

    "coder": """Tu es un expert en programmation Python et architecture logicielle.
Ta t√¢che : produire du code de qualit√© professionnelle.

STANDARDS :
1. Code propre, lisible, bien comment√©
2. Gestion des erreurs appropri√©e
3. Typing hints quand pertinent
4. Docstrings pour les fonctions publiques
5. Explique bri√®vement les choix techniques si n√©cessaire

Si on te demande d'analyser du code existant :
- Identifie les probl√®mes potentiels
- Propose des am√©liorations concr√®tes
- Fournis des exemples de code corrig√©""",
}


def consult_expert(
    query: str,
    expertise: str = "reasoning",
    context: Optional[str] = None
) -> Dict[str, Any]:
    """
    Consulte un mod√®le expert de mani√®re STATELESS.
    
    L'expert ne re√ßoit QUE la query (et optionnellement du contexte documentaire),
    mais JAMAIS l'historique de bavardage r√©cent d'Iris. Cela garantit une
    r√©ponse non contamin√©e par la conversation en cours.
    
    Args:
        query: La question complexe ou historique √† v√©rifier
        expertise: Type d'expert requis
            - 'reasoning' : Analyse complexe, logique profonde (Thinking model)
            - 'historian' : V√©rification factuelle, dates, √©v√©nements (Pro model)
            - 'coder' : Code, architecture, debugging (Flash exp)
        context: Contexte documentaire optionnel (extraits de m√©moire, donn√©es trouv√©es)
                 ‚ö†Ô∏è NE PAS passer l'historique de conversation ici !
    
    Returns:
        dict avec:
            - status: "success" ou "error"
            - response: R√©ponse de l'expert
            - model_used: Mod√®le effectivement utilis√©
            - expertise: Type d'expertise demand√©
            - error: Message d'erreur si √©chec
    """
    # Validation des entr√©es
    if not query or not query.strip():
        return {
            "status": "error",
            "error": "Le param√®tre 'query' est obligatoire et ne peut pas √™tre vide",
            "expertise": expertise,
            "model_used": None
        }
    
    # 1. S√©lectionner le mod√®le
    model = EXPERT_MODELS.get(expertise, DEFAULT_EXPERT_MODEL)
    
    if expertise not in EXPERT_MODELS:
        logger.warning(f"‚ö†Ô∏è Expertise inconnue '{expertise}', fallback vers {DEFAULT_EXPERT_MODEL}")
    
    logger.info(f"üéì Consultation expert: {expertise} ‚Üí {model}")
    logger.info(f"   Query: {query[:100]}{'...' if len(query) > 100 else ''}")
    if context:
        logger.info(f"   Contexte fourni: {len(context)} caract√®res")
    
    # 2. R√©cup√©rer les instructions syst√®me pour cette expertise
    system_instruction = EXPERT_INSTRUCTIONS.get(
        expertise, 
        "Tu es un expert consult√© pour une question sp√©cifique. R√©ponds de mani√®re factuelle et pr√©cise."
    )
    
    # 3. Construire le message final (stateless - pas d'historique)
    message_parts = []
    
    # Instructions syst√®me en premier
    message_parts.append(system_instruction)
    message_parts.append("\n" + "="*50 + "\n")
    
    # Contexte documentaire si fourni
    if context and context.strip():
        message_parts.append("CONTEXTE DOCUMENTAIRE (donn√©es de la m√©moire) :")
        message_parts.append("-" * 40)
        message_parts.append(context.strip())
        message_parts.append("-" * 40)
        message_parts.append("")
    
    # La question
    message_parts.append("QUESTION √Ä ANALYSER :")
    message_parts.append(query.strip())
    
    full_message = "\n".join(message_parts)
    
    # 4. Instancier un provider TEMPORAIRE avec le bon mod√®le
    try:
        expert_provider = GeminiProvider(
            model=model, 
            enable_grounding=False  # Pas de web search pour les experts
        )
        
        # Appel one-shot : chat() sans historique, sans contexte conversationnel
        # C'est la cl√© du stateless - on ne passe PAS l'historique d'Iris
        response = expert_provider.chat(full_message)
        
        # V√©rifier qu'on a une r√©ponse valide
        if not response or not response.strip():
            logger.warning(f"‚ö†Ô∏è R√©ponse expert vide")
            return {
                "status": "error",
                "error": "L'expert a retourn√© une r√©ponse vide",
                "model_used": model,
                "expertise": expertise
            }
        
        logger.info(f"‚úÖ R√©ponse expert re√ßue ({len(response)} caract√®res)")
        
        return {
            "status": "success",
            "response": response,
            "model_used": model,
            "expertise": expertise
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur consultation expert: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "status": "error",
            "error": str(e),
            "model_used": model,
            "expertise": expertise
        }


# === FONCTION UTILITAIRE POUR LE WRAPPER ===
def format_expert_response(result: Dict[str, Any]) -> str:
    """
    Formate la r√©ponse de l'expert pour injection dans la r√©ponse d'Iris.
    Utilis√© par hermes_wrapper.py
    """
    if result.get("status") == "success":
        expertise = result.get("expertise", "unknown")
        model = result.get("model_used", "unknown")
        response = result.get("response", "")
        
        # En-t√™te discret pour tra√ßabilit√©
        header = f"üéì Analyse expert ({expertise}):\n"
        return header + response
    else:
        return f"Erreur consultation expert: {result.get('error', 'Erreur inconnue')}"


# === TEST ===
if __name__ == "__main__":
    import sys
    
    print("=" * 60)
    print("CONSULT_EXPERT v1.0.0 - Test Architecture MoA")
    print("=" * 60)
    
    # V√©rifier que le provider Gemini est accessible
    try:
        from utils.gemini_provider import GeminiProvider
        print("‚úÖ Import GeminiProvider r√©ussi")
    except ImportError as e:
        print(f"‚ùå Erreur import: {e}")
        print("   Ce test doit √™tre lanc√© depuis le dossier app/")
        sys.exit(1)
    
    # Test 1: Expertise reasoning
    print("\n" + "-" * 40)
    print("TEST 1: Expertise 'reasoning'")
    print("-" * 40)
    result = consult_expert(
        query="Si tous les A sont B, et certains B sont C, peut-on conclure que certains A sont C?",
        expertise="reasoning"
    )
    print(f"Status: {result['status']}")
    print(f"Mod√®le: {result['model_used']}")
    if result['status'] == 'success':
        print(f"R√©ponse (extrait): {result['response'][:300]}...")
    else:
        print(f"Erreur: {result.get('error')}")
    
    # Test 2: Expertise historian avec contexte
    print("\n" + "-" * 40)
    print("TEST 2: Expertise 'historian' avec contexte")
    print("-" * 40)
    result = consult_expert(
        query="Quand le projet MOSS a-t-il √©t√© cr√©√© d'apr√®s ce contexte?",
        expertise="historian",
        context="Extrait m√©moire: Le 15 octobre 2024, Serge a mentionn√© d√©marrer un nouveau projet appel√© MOSS pour la m√©moire persistante."
    )
    print(f"Status: {result['status']}")
    print(f"Mod√®le: {result['model_used']}")
    if result['status'] == 'success':
        print(f"R√©ponse (extrait): {result['response'][:300]}...")
    else:
        print(f"Erreur: {result.get('error')}")
    
    # Test 3: Expertise coder
    print("\n" + "-" * 40)
    print("TEST 3: Expertise 'coder'")
    print("-" * 40)
    result = consult_expert(
        query="√âcris une fonction Python pour calculer la similarit√© cosinus entre deux vecteurs",
        expertise="coder"
    )
    print(f"Status: {result['status']}")
    print(f"Mod√®le: {result['model_used']}")
    if result['status'] == 'success':
        print(f"R√©ponse (extrait): {result['response'][:500]}...")
    else:
        print(f"Erreur: {result.get('error')}")
    
    # Test 4: Expertise inconnue (fallback)
    print("\n" + "-" * 40)
    print("TEST 4: Expertise inconnue (test fallback)")
    print("-" * 40)
    result = consult_expert(
        query="Quelle est la capitale de la France?",
        expertise="geographe"  # N'existe pas
    )
    print(f"Status: {result['status']}")
    print(f"Mod√®le utilis√© (fallback): {result['model_used']}")
    
    print("\n" + "=" * 60)
    print("Tests termin√©s!")
    print("=" * 60)
