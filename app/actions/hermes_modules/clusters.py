"""
hermes_modules/clusters.py - Expansion de requ√™tes via Word2Vec
MOSS v0.10.4 - Session 70

Utilise un mod√®le Word2Vec pr√©-entra√Æn√© pour enrichir les requ√™tes
avec des termes s√©mantiquement similaires.

Exemple:
    Requ√™te: "m√©moire externe"
    Expansion: ["m√©moire", "externe", "m√©moire_persistante", "m√©moire_d√©localis√©e", 
                "stockage", "ssd", "m√©moire_agnostique"]

Usage dans core.py:
    from .clusters import expand_query
    
    def run(params):
        query = params.get("query", "")
        expanded_terms = expand_query(query)  # ~10-50ms
        query_params = _parse_query(query, extra_terms=expanded_terms)
        ...
"""

import re
import unicodedata
import logging
from pathlib import Path
from typing import List, Set, Optional, Tuple

logger = logging.getLogger(__name__)

# === CONFIGURATION ===
MEMORY_DIR = Path.home() / "Dropbox" / "aiterego_memory"
MODEL_PATH = MEMORY_DIR / "models" / "clusters.model"

# Fallback si le mod√®le n'est pas dans models/
LEGACY_MODEL_PATH = MEMORY_DIR / "clusters_full.model"

# Param√®tres d'expansion
DEFAULT_TOP_N = 5           # Nombre de termes similaires par mot
DEFAULT_MIN_SIMILARITY = 0.5  # Seuil de similarit√© minimum
MAX_EXPANSION_TERMS = 15    # Maximum de termes ajout√©s au total

# Stopwords √† ne pas expander
STOPWORDS = {
    'le', 'la', 'les', 'de', 'du', 'des', 'un', 'une', 'et', 'est', 'en',
    'que', 'qui', 'dans', 'pour', 'sur', 'avec', 'ce', 'se', 'ne', 'pas',
    'je', 'tu', 'il', 'nous', 'vous', 'on', 'tout', 'bien', 'tr√®s',
    'the', 'a', 'an', 'is', 'are', 'to', 'of', 'in', 'for', 'on', 'with'
}

# Cache du mod√®le (singleton)
_model = None
_model_loaded = False


def _normalize_text(text: str) -> str:
    """Normalise le texte (accents ‚Üí ASCII)."""
    normalized = unicodedata.normalize('NFD', text)
    return normalized.encode('ascii', 'ignore').decode('utf-8').lower()


def _load_model():
    """Charge le mod√®le Word2Vec (lazy loading, singleton)."""
    global _model, _model_loaded
    
    if _model_loaded:
        return _model
    
    _model_loaded = True
    
    # Chercher le mod√®le
    model_path = None
    if MODEL_PATH.exists():
        model_path = MODEL_PATH
    elif LEGACY_MODEL_PATH.exists():
        model_path = LEGACY_MODEL_PATH
    
    if not model_path:
        logger.warning(f"‚ö†Ô∏è Mod√®le Word2Vec non trouv√©: {MODEL_PATH}")
        return None
    
    try:
        from gensim.models import Word2Vec
        _model = Word2Vec.load(str(model_path))
        logger.info(f"‚ú® Word2Vec charg√©: {len(_model.wv)} termes")
        return _model
    except ImportError:
        logger.warning("‚ö†Ô∏è gensim non install√© - expansion d√©sactiv√©e")
        return None
    except Exception as e:
        logger.error(f"‚ùå Erreur chargement Word2Vec: {e}")
        return None


def get_similar_terms(
    term: str,
    top_n: int = DEFAULT_TOP_N,
    min_similarity: float = DEFAULT_MIN_SIMILARITY
) -> List[Tuple[str, float]]:
    """
    Retourne les termes similaires √† un mot donn√©.
    
    Args:
        term: Le terme √† rechercher
        top_n: Nombre maximum de r√©sultats
        min_similarity: Score minimum (0-1)
    
    Returns:
        Liste de tuples (terme, score)
    """
    model = _load_model()
    if not model:
        return []
    
    # Normaliser le terme
    term_normalized = _normalize_text(term)
    
    # Essayer le terme original et normalis√©
    for t in [term.lower(), term_normalized]:
        if t in model.wv:
            try:
                similaires = model.wv.most_similar(t, topn=top_n)
                # Filtrer par seuil de similarit√©
                return [(mot, score) for mot, score in similaires if score >= min_similarity]
            except Exception:
                pass
    
    return []


def expand_query(
    query: str,
    top_n: int = DEFAULT_TOP_N,
    min_similarity: float = DEFAULT_MIN_SIMILARITY,
    max_terms: int = MAX_EXPANSION_TERMS
) -> List[str]:
    """
    Expande une requ√™te avec des termes s√©mantiquement similaires.
    
    Args:
        query: La requ√™te originale
        top_n: Termes similaires par mot source
        min_similarity: Score minimum
        max_terms: Maximum de termes ajout√©s
    
    Returns:
        Liste des termes d'expansion (sans les termes originaux)
    
    Exemple:
        >>> expand_query("m√©moire externe")
        ['m√©moire_persistante', 'stockage', 'ssd', 'm√©moire_agnostique']
    """
    model = _load_model()
    if not model:
        return []
    
    # Tokeniser la requ√™te
    words = re.findall(r'[a-z√†√¢√§√©√®√™√´√Ø√Æ√¥√π√ª√º√ø≈ì√¶√ß0-9]+', query.lower())
    
    # Filtrer les stopwords et mots trop courts
    query_terms = {w for w in words if w not in STOPWORDS and len(w) > 2}
    
    if not query_terms:
        return []
    
    # Collecter les expansions
    expansions: Set[str] = set()
    
    for term in query_terms:
        similaires = get_similar_terms(term, top_n=top_n, min_similarity=min_similarity)
        for mot, score in similaires:
            # Ne pas ajouter les termes d√©j√† dans la requ√™te
            mot_clean = mot.replace('_', ' ')  # "m√©moire_externe" ‚Üí "m√©moire externe"
            if mot not in query_terms and mot_clean not in query.lower():
                expansions.add(mot)
    
    # Limiter le nombre total
    result = list(expansions)[:max_terms]
    
    if result:
        logger.debug(f"üîç Expansion '{query}': +{len(result)} termes")
    
    return result


def expand_query_with_scores(
    query: str,
    top_n: int = DEFAULT_TOP_N,
    min_similarity: float = DEFAULT_MIN_SIMILARITY
) -> List[Tuple[str, float]]:
    """
    Comme expand_query mais retourne aussi les scores de similarit√©.
    Utile pour le debugging ou le scoring pond√©r√©.
    """
    model = _load_model()
    if not model:
        return []
    
    words = re.findall(r'[a-z√†√¢√§√©√®√™√´√Ø√Æ√¥√π√ª√º√ø≈ì√¶√ß0-9]+', query.lower())
    query_terms = {w for w in words if w not in STOPWORDS and len(w) > 2}
    
    if not query_terms:
        return []
    
    expansions: dict = {}  # mot ‚Üí meilleur score
    
    for term in query_terms:
        similaires = get_similar_terms(term, top_n=top_n, min_similarity=min_similarity)
        for mot, score in similaires:
            if mot not in query_terms:
                # Garder le meilleur score si le mot appara√Æt plusieurs fois
                if mot not in expansions or score > expansions[mot]:
                    expansions[mot] = score
    
    # Trier par score d√©croissant
    result = sorted(expansions.items(), key=lambda x: x[1], reverse=True)
    return result[:MAX_EXPANSION_TERMS]


def get_model_stats() -> dict:
    """Retourne des statistiques sur le mod√®le."""
    model = _load_model()
    if not model:
        return {"status": "not_loaded", "vocab_size": 0}
    
    return {
        "status": "loaded",
        "vocab_size": len(model.wv),
        "vector_size": model.wv.vector_size,
        "model_path": str(MODEL_PATH if MODEL_PATH.exists() else LEGACY_MODEL_PATH)
    }


# === TEST ===
if __name__ == "__main__":
    print("=" * 60)
    print("üß™ TEST EXPANSION WORD2VEC")
    print("=" * 60)
    
    # Stats
    stats = get_model_stats()
    print(f"\nüìä Mod√®le: {stats}")
    
    # Tests d'expansion
    requetes_test = [
        "m√©moire externe",
        "Alex et J√©r√©mie",
        "brevet MOSS",
        "Karen Barad posthumanisme",
        "architecture syst√®me",
        "scribe extraction"
    ]
    
    for query in requetes_test:
        expansions = expand_query(query)
        print(f"\nüîç '{query}'")
        if expansions:
            print(f"   ‚Üí +{len(expansions)}: {expansions[:8]}...")
        else:
            print(f"   ‚Üí (aucune expansion)")
    
    # Test avec scores
    print(f"\n{'='*60}")
    print("üìä EXPANSION AVEC SCORES")
    print(f"{'='*60}")
    
    expansions_scores = expand_query_with_scores("m√©moire externe")
    for mot, score in expansions_scores[:10]:
        print(f"   {score:.3f} - {mot}")
